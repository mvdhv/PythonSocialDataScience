{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "18hcjR0ktnOyexb_7m_zFMYEvkM5KJFIs",
      "authorship_tag": "ABX9TyNyBRxUK5zqTUScst5LULYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aelshehawy/PythonSocialDataScience/blob/main/Session_5_Python23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Today's Plan**\n",
        "\n",
        "\n",
        "- Pandas Revision\n",
        "- Mini Visualization\n",
        "- Scraping the Web\n",
        "- Twitter API\n",
        "- Mini NLP"
      ],
      "metadata": {
        "id": "4cs6biw_7ZWP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhbas_4Dtd2F"
      },
      "source": [
        "# **Pandas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZW5x0Aetd2F"
      },
      "source": [
        "\n",
        "![pandas1](https://media.giphy.com/media/Wa5JDuv6kzoTC/giphy.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwUxqvTXtd2G"
      },
      "source": [
        "## Why is Pandas AMAZING?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9qxYdkjtd2G"
      },
      "source": [
        "1. super easy loading in data\n",
        "2. easy data cleaning\n",
        "3. easy data manipulation\n",
        "4. easy merging and extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A pandas Series is a one-dimensional array. It holds any data type supported in Python and uses labels to locate each data value for retrieval."
      ],
      "metadata": {
        "id": "qezzM39S7wPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "ser = pd.Series([\"My\", \"name\", \"is\", \"ash\", \"hello\"])\n",
        "ser"
      ],
      "metadata": {
        "id": "FsJ1PTt3f-Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser = pd.Series([\"My\", \"name\", \"is\", \"ash\", \"hello\"], index = [1,2,3,4,5])\n",
        "ser"
      ],
      "metadata": {
        "id": "IcdmYl9egOMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the data as a dict of lists:\n",
        "\n",
        "We will create again a shopping list!\n"
      ],
      "metadata": {
        "id": "51Yl1adcgblr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = {\n",
        "    'drygroceries': [\"pasta\", \"rice\", \"coffee\", \"beans\"],\n",
        "    'milkproducts': [\"cheese\", \"cream\", \"sour cream\", \"yogurt\"],\n",
        "    'drinks': ['tea', 'coffee', 'water', 'juice']\n",
        "}"
      ],
      "metadata": {
        "id": "jiqYxjnWgbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Index is also optional\n",
        "my_index = ['a', 'b', 'c', 'd']"
      ],
      "metadata": {
        "id": "WvAjajY3gklb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=my_data,index=my_index)\n",
        "df"
      ],
      "metadata": {
        "id": "q_Pdny9WgiJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLYIH1hHtd2G"
      },
      "source": [
        "### Lets learn to load data in pandas\n",
        "\n",
        "We are going to start with yesterdays data - German Sputnik Newspaper articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVhHXqTrtd2H"
      },
      "source": [
        "**Lets try with pandas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yw_K_mJtd2H"
      },
      "outputs": [],
      "source": [
        "sputnikdata1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Oxford Text Analysis 22/Python QTA Drive Oxford 2022/Data/sputnikgerman20.tsv')\n",
        "\n",
        "#why do we get an error message?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iLbAFjGtd2I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sputnikdata1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Oxford Text Analysis 22/Python QTA Drive Oxford 2022/Data/sputnikgerman20.tsv',sep='\\t')\n",
        "sputnikdata1.head()\n",
        "#what do we want to change here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4ddtvO7td2I"
      },
      "outputs": [],
      "source": [
        "#first line is not header\n",
        "sputnikdata = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Oxford Text Analysis 22/Python QTA Drive Oxford 2022/Data/sputnikgerman20.tsv',sep='\\t', header=None)\n",
        "sputnikdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYGoYltAtd2I"
      },
      "source": [
        "## Select Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJx-yXALtd2I"
      },
      "source": [
        "### how would I select the date?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBJbBxe8td2J"
      },
      "outputs": [],
      "source": [
        "sputnikdata_date=sputnikdata[2]\n",
        "sputnikdata_date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WQwCxsQtd2J"
      },
      "source": [
        "### Select only content and title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8taBZFctd2J"
      },
      "outputs": [],
      "source": [
        "sputnikdata_content_title=sputnikdata[[3,4]]\n",
        "sputnikdata_content_title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmDtLEJtd2J"
      },
      "source": [
        "## Select rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu-HDvtftd2K"
      },
      "outputs": [],
      "source": [
        "#select 0-5\n",
        "\n",
        "sputnikdata_rows=sputnikdata[0:1]\n",
        "sputnikdata_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzFPSMBgtd2M"
      },
      "source": [
        "## Exporting data from Pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "plxsmC_5td2N"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"mydata.csv\", sep='\\t', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ruTl8ONupCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOPvjGRDQWrZ"
      },
      "source": [
        "## Combining Datasets\n",
        "\n",
        "We look at two commands in particular. For an in-depth explanation, see: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRBU2m2JNf9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Oxford Text Analysis 22/Python QTA Drive Oxford 2022/Data/sputnikgerman20.tsv',sep='\\t',header=None)\n",
        "df"
      ],
      "metadata": {
        "id": "t27XfwVfUx6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#what if I want to rename?\n",
        "\n",
        "col_name_dict =  {\n",
        "    0: 'link1',\n",
        "    1: 'link2',\n",
        "    2: 'date',\n",
        "    3: 'title',\n",
        "    4: 'text',\n",
        "    5: 'marker',\n",
        "    6: 'keywords',\n",
        "    7: 'numberwords',\n",
        "    8: 'score'\n",
        "}\n",
        "df = df.rename(col_name_dict, axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "LCh53J71W7Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "HZLErE48U9mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_5zyvZqQWrZ"
      },
      "outputs": [],
      "source": [
        "df1 = df.loc[:, ['link1', 'link2', 'title']]\n",
        "df2 = df.loc[:, ['date', 'text','link1']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "EgNgKS5dUlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "8zWusFc7UmJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhlvJJ-mQWrZ"
      },
      "outputs": [],
      "source": [
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTEz45CwQWrZ"
      },
      "source": [
        "### `pd.merge`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHCz3245QWrZ"
      },
      "outputs": [],
      "source": [
        "pd.merge(df1, df2, on=\"link1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization through counting"
      ],
      "metadata": {
        "id": "C3v3R-eQUiGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets pre-process text"
      ],
      "metadata": {
        "id": "JcRUtwIKSxXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "exclude = set(string.punctuation) # if you see this not part of the punctuation -->”\n",
        "import nltk\n",
        "nltk.download('stopwords') #you can also download all libraries in nltk at once\n",
        "from nltk.corpus import stopwords\n",
        "stop_word_list = stopwords.words('german')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def nlp_simple_pipeline(text):\n",
        "    \n",
        "    #it depends if the words have been lowercased or not\n",
        "    text = text.lower()\n",
        "    text=text.split()\n",
        "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
        "    text = [token for token in text if token not in stop_word_list]\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "D1sFZNqTSwxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_zS7sWIiGFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Oxford Text Analysis 22/Python QTA Drive Oxford 2022/Data/sputnikgerman20.tsv',sep='\\t',header=None)\n",
        "dataframe"
      ],
      "metadata": {
        "id": "H-qMxNOjQxzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe[\"cleanedtitle\"]=dataframe[3].apply(nlp_simple_pipeline) \n",
        "dataframe"
      ],
      "metadata": {
        "id": "mN26tF05O9Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['text'] =dataframe['cleanedtitle'].apply(lambda x: ' '.join(x))\n"
      ],
      "metadata": {
        "id": "UaPPeZ_BPijl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "id": "3xOE1JTRPkHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "#lets count"
      ],
      "metadata": {
        "id": "LLs7h5OWPZxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets plot"
      ],
      "metadata": {
        "id": "Q7UX_fdjMved"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **How does Webscraping work?**\n",
        "1: Send a request to download the site’s content.\n",
        "\n",
        "2: Filter the page’s HTML to look for the nedded tags.\n",
        "\n",
        "3: Print the text inside the target tags, producing the output in the format previously specified in the code."
      ],
      "metadata": {
        "id": "xIqYYtn2NAAk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_eKTnEGwTL"
      },
      "source": [
        "## Requests\n",
        "\n",
        "We use the `requests` library to make `html` requests and retrieve webpages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ-10LfiGwTL"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtpZiRsGwTM"
      },
      "source": [
        "\n",
        "You need to send an HTTP request to the server of the page you want to scrape. \n",
        "\n",
        "The server sends the HTML content of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PvVoWWmGwTM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOkg0FmhGwTM"
      },
      "source": [
        "## BeautifulSoup\n",
        "\n",
        "BeautifulSoup contains tools for navigating `html` code.\n",
        "\n",
        "\"Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. It is a tool for web scraping that helps you clean up and parse the documents you have pulled down from the web.\"\n",
        "\n",
        "Read more here: https://programminghistorian.org/en/lessons/retired/intro-to-beautiful-soup\n",
        "\n",
        "**HTML: standard markup language for documents designed to be displayed in a web browser.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iL6EyYzGwTM"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAcQYhtDIVjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15hX3ia9GwTM"
      },
      "outputs": [],
      "source": [
        "#we use the html parser\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ftcZWpHGwTM"
      },
      "outputs": [],
      "source": [
        "# We print content of the document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QBvs65GGwTM"
      },
      "outputs": [],
      "source": [
        "# We want to get all the links to the page\n",
        "# We can use the page \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets use a loop to print out all the content within the ahref label\n",
        "\n"
      ],
      "metadata": {
        "id": "wDLR6BFPZUM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoA_xVlxcaJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cU1Xev9GwTM"
      },
      "outputs": [],
      "source": [
        "# That output is annoying, so let's use some regex to remove whitespace\n",
        "\n",
        "    #result = re.sub(pattern, repl, string, count=0, flags=0);\n",
        "    #\\s: white space charachter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoAyjikuGwTM"
      },
      "outputs": [],
      "source": [
        "# It'd be easier to read in a table, so let's use pandas!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🐦 ***Twitter Mini Session***"
      ],
      "metadata": {
        "id": "UujtOyhlgrSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets get started**"
      ],
      "metadata": {
        "id": "4Gpe-fJdgrSs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk5NexFggrSs"
      },
      "source": [
        "1. Register your application\n",
        "https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api\n",
        "\n",
        "2. Save you applications Consumer Key and Consumer Secret from the application details tab.\n",
        "\n",
        "\n",
        "**More detailed instruction**\n",
        "\n",
        "1. Have a Twitter Account\n",
        "\n",
        "2. Apply for for a developer account and describe your intended use\n",
        "\n",
        "3. Review your access application and read TOS\n",
        "\n",
        "5. Set up and application\n",
        "\n",
        "6. Copy your tokens\n",
        "\n",
        "Get your needed authentication\n",
        "https://developer.twitter.com/en\n",
        "\n",
        "API Limits\n",
        "https://developer.twitter.com/en/docs/basics/rate-limits &\n",
        "https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBWy52hxgrSt"
      },
      "source": [
        "## Twython API to access Twitter Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install twython\n",
        "!pip install twython"
      ],
      "metadata": {
        "id": "4fm4NhFZgrSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wCOtwYBmgrSt"
      },
      "outputs": [],
      "source": [
        "#using an API\n",
        "# to install the library:\n",
        "# pip install twython\n",
        "\n",
        "# how to find the documentation, just google name of the library + documentation\n",
        "# this is the twithon documentation: https://twython.readthedocs.io/en/latest/\n",
        "\n",
        "from twython import Twython\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Dm73qPN5grSt"
      },
      "outputs": [],
      "source": [
        "#you can then post on your own timeline from within Python\n",
        "#twitter_api.update_status(status=\"Hello world.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets search for a certain user"
      ],
      "metadata": {
        "id": "OHIEJEX9grSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we will try an example that fetches popular tweets that mention Boris Johnson's account**\n",
        "\n",
        "If you want to learn more about standard search operators, you will find information here\n",
        "https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators"
      ],
      "metadata": {
        "id": "NUaPYwL7grSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "E_k5VW7RgrSt"
      },
      "outputs": [],
      "source": [
        "# here you search - to get them ordered by time, change popular with recent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZjvJFypgrSt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoM-BVtMgrSt"
      },
      "outputs": [],
      "source": [
        "#what object do we receive back? #read documentation or use:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFPUDKNGgrSt"
      },
      "outputs": [],
      "source": [
        "# which keys do we have in the dictionary?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTYSY-6tgrSu"
      },
      "outputs": [],
      "source": [
        "# which object do we have into \"statuses\"?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKStY-xXgrSu"
      },
      "outputs": [],
      "source": [
        "# we create a new variable, called \"tweets\" and we put the content of \"search[\"statuses\"]\" there \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nUVLAeKgrSu"
      },
      "outputs": [],
      "source": [
        "# we can get the text out!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9V7VXJtgrSu"
      },
      "source": [
        "## Hashtags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mSpU64IDgrSu"
      },
      "outputs": [],
      "source": [
        "\n",
        "#here we use the twitter api to search for the most recent 100 tweets that use #russia\n",
        "\n",
        "#i extract the statuses of those tweets that use the hashtag russia and save them, statuses would include the text that I need\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#search2 \n",
        "#check the dictionary structure if needed"
      ],
      "metadata": {
        "id": "sQv_cf3lgrSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmY0w-4agrSu"
      },
      "outputs": [],
      "source": [
        "#here I want to extract the text from each of the statuses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- turn that into a pandas data frame\n",
        "- clean text\n"
      ],
      "metadata": {
        "id": "Z6MctpfagrSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q5nRPTE_grSu"
      },
      "outputs": [],
      "source": [
        "#extract hashtags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CacYLYlgrSu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5MDY6CFgrSu"
      },
      "outputs": [],
      "source": [
        "#the counter library is a very important and powerful library\n",
        "#it helps us simply count stuff\n",
        "#lets count hashtags\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8pGnbY9grSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNzR8dOtgrSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put as pandas df\n",
        "import pandas\n"
      ],
      "metadata": {
        "id": "EIVMO766grSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot counts\n"
      ],
      "metadata": {
        "id": "CDkMHsUMgrSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basics of NLP on Tweets"
      ],
      "metadata": {
        "id": "9BzuEb2GkCxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load your tweets - find them on github"
      ],
      "metadata": {
        "id": "GBU3r3fr1rBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lets clean our text - Pre-Processing"
      ],
      "metadata": {
        "id": "VrP5Y6NYk3s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#turn to pandas\n"
      ],
      "metadata": {
        "id": "7XeQQAEYmBPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# task clean the text"
      ],
      "metadata": {
        "id": "fR6baDmUla28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2cfPssNlz9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjq-wAkgmdcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLCwfVkI80za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Clouds"
      ],
      "metadata": {
        "id": "-IHhrWJJ81U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the wordcloud library\n",
        "from wordcloud import WordCloud\n",
        "# Join the different processed titles together.\n",
        "\n",
        "\n",
        "# Create a WordCloud object\n",
        "\n",
        "\n",
        "# Generate a word cloud\n",
        "\n",
        "\n",
        "# Visualize the word cloud\n"
      ],
      "metadata": {
        "id": "yO3mv9Zx3ZjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "c6w-hMi37KwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pos-Tagging"
      ],
      "metadata": {
        "id": "WD7i_byx83JH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wlGRQRHY493t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract nouns"
      ],
      "metadata": {
        "id": "7Kw4ZQ4k7RcL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BemzP9lq7SpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition"
      ],
      "metadata": {
        "id": "vQ2WO9W_8xm9"
      }
    }
  ]
}
